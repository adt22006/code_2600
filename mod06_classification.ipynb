{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ed685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from ISLP import (load_data, confusion_table)\n",
    "from ISLP.models import (ModelSpec as MS, summarize, contrast)\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n",
    "\n",
    "roc_curve_est = RocCurveDisplay.from_estimator \n",
    "roc_curve_pred = RocCurveDisplay.from_predictions \n",
    "\n",
    "\n",
    "# set seed\n",
    "seed = 5331"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205b0af",
   "metadata": {},
   "source": [
    "### We will use the OJ dataset, which contains information about orange juice purchases across different stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c212154",
   "metadata": {},
   "outputs": [],
   "source": [
    "OJ = load_data('OJ')\n",
    "OJ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c076ad89",
   "metadata": {},
   "source": [
    "### What are the variables and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24390cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OJ.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016e739",
   "metadata": {},
   "source": [
    "### We will use all stores other than ID=7 as training data, and Store #7 will be used as test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1eedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OJ[\"StoreID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94daafb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = OJ[OJ['StoreID'] != 7]\n",
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e13fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = OJ[OJ['StoreID']==7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbdeae",
   "metadata": {},
   "source": [
    "### We will predict whether each customer purchased Citrus Hill or Minute Maid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Train.Purchase == 'CH'\n",
    "y_test = Test.Purchase == 'CH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1825f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train[['WeekofPurchase', 'PriceCH', 'PriceMM', 'DiscCH', 'DiscMM', 'SpecialCH', 'SpecialMM', 'LoyalCH', 'SalePriceCH', 'SalePriceMM', 'PriceDiff', 'PctDiscCH', 'PctDiscMM', 'ListPriceDiff']]\n",
    "X_test = Test[['WeekofPurchase', 'PriceCH', 'PriceMM', 'DiscCH', 'DiscMM', 'SpecialCH', 'SpecialMM', 'LoyalCH', 'SalePriceCH', 'SalePriceMM', 'PriceDiff', 'PctDiscCH', 'PctDiscMM', 'ListPriceDiff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plots before drawing them\n",
    "nrows = 5\n",
    "ncols = 3\n",
    "figsize = (5*nrows, 10*ncols)\n",
    "\n",
    "fig, axes = subplots(nrows=nrows,\n",
    "                     ncols=ncols,\n",
    "                     figsize=figsize)\n",
    "\n",
    "# Assign a grid location to each index\n",
    "def range_to_grid(i, nrows, ncols):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for n in range(nrows*ncols):\n",
    "        x.append(n // ncols)\n",
    "        y.append(n % ncols)\n",
    "        # print(n,x[n],y[n]) # for testing this function\n",
    "    return x[i],y[i]\n",
    "\n",
    "# Plot the variables as paired boxplots\n",
    "for j, col in enumerate(X_train.columns):\n",
    "    r, c = range_to_grid(j, nrows, ncols)\n",
    "    ax = axes[r, c]\n",
    "\n",
    "    data_0 = X_train.loc[y_train == 0, col]\n",
    "    data_1 = X_train.loc[y_train == 1, col]\n",
    "\n",
    "    ax.boxplot(\n",
    "        [data_0, data_1],\n",
    "        labels=[\"y = 0\", \"y = 1\"],\n",
    "        showfliers=False\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['intercept'] = np.ones(X_train.shape[0])\n",
    "X_test['intercept'] = np.ones(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a7d4f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7712f",
   "metadata": {},
   "source": [
    "### Since the many of the variables are correlated, a model with all of them will likely be overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "initial_glm = sm.GLM(y_train,\n",
    "             X_train,\n",
    "             family=sm.families.Binomial())\n",
    "\n",
    "# fit model\n",
    "initial_results = initial_glm.fit()\n",
    "\n",
    "# analyze model\n",
    "summarize(initial_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b825ef",
   "metadata": {},
   "source": [
    "### Create a logistic model using only the intercept, Citrus Hill loyalty, and the difference in price between the brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = #fillin\n",
    "\n",
    "# build model\n",
    "glm = #fillin\n",
    "\n",
    "# fit model\n",
    "results = #fillin\n",
    "\n",
    "# analyze model\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c961d91",
   "metadata": {},
   "source": [
    "### Get the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, model):\n",
    "    # the built-in get_prediction tool returns an array, so we need to convert to a dataframe\n",
    "    predictions_df = pd.DataFrame(model.get_prediction(X).predicted, columns=['y_hat'], index=X.index)\n",
    "    return predictions_df['y_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5246e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train=predict(X_train[var_list],results)\n",
    "probs_test=predict(X_test[var_list],results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64392be2",
   "metadata": {},
   "source": [
    "### We'll use 0.5 as the threshold for True vs. False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = np.array([True]*len(y_train))\n",
    "predictions_train[probs_train<0.5] = False\n",
    "\n",
    "predictions_test = np.array([True]*len(y_test))\n",
    "predictions_test[probs_test<0.5] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c6bea",
   "metadata": {},
   "source": [
    "### Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = confusion_table(predictions_train, y_train)\n",
    "train_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b75b21",
   "metadata": {},
   "source": [
    "### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_table = confusion_table(predictions_test, y_test)\n",
    "test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d33ba",
   "metadata": {},
   "source": [
    "### Calculate the false positive rate and false negative rate for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d126d93",
   "metadata": {},
   "source": [
    "You can hard code the exact numbers to at least **three** decimal places, or you can code a formula that correcly calculates this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc04c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = #fillin\n",
    "print(\"fpr =\",false_positive_rate)\n",
    "false_negative_rate = #fillin\n",
    "print(\"fnr =\",false_negative_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91528d22",
   "metadata": {},
   "source": [
    "## Naive Bayes and k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f70418",
   "metadata": {},
   "source": [
    "### Create arrays of train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list.remove('intercept')\n",
    "\n",
    "X_train_array, X_test_array = [np.asarray(X) for X in [X_train[var_list], X_test[var_list]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d0e01",
   "metadata": {},
   "source": [
    "### Build Naive Bayes classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = GaussianNB()\n",
    "naive.fit(X_train_array, y_train)\n",
    "naive_test = naive.predict(X_test_array)\n",
    "naive_probs = naive.predict_proba(X_test_array)[:,1]\n",
    "\n",
    "confusion_table(naive_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06fbc4",
   "metadata": {},
   "source": [
    "### Try different k-Nearest Neigbors classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef842c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try 5 nearest neighbors\n",
    "\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn5.fit(X_train_array, y_train)\n",
    "knn5_test = knn5.predict(X_test_array)\n",
    "\n",
    "confusion_table(knn5_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7abdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about 50 nearest neighbors?\n",
    "\n",
    "knn50 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn50.fit(X_train_array, y_train)\n",
    "knn50_test = knn50.predict(X_test_array)\n",
    "\n",
    "confusion_table(knn50_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786946c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about 500 nearest neighbors?\n",
    "\n",
    "knn500 = KNeighborsClassifier(n_neighbors=500)\n",
    "knn500.fit(X_train_array, y_train)\n",
    "knn500_test = knn500.predict(X_test_array)\n",
    "\n",
    "confusion_table(knn500_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cfbce",
   "metadata": {},
   "source": [
    "### Write a loop to test all kNN models from k=1 to 500. \n",
    "\n",
    "### Return the lowest value of k which maximizes the number of correct predictions on the test set. You can obtain these numbers from the main diagonal of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = 0\n",
    "num_correct_pred = 0\n",
    "\n",
    "for k in range(1,500):\n",
    "    #fillin\n",
    "\n",
    "print(best_k)\n",
    "print(num_correct_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989003f",
   "metadata": {},
   "source": [
    "### Now that you've found an optimal choice of k, let's construct that model and store it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046dc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_opt = KNeighborsClassifier(n_neighbors=#fillin\n",
    "                               )\n",
    "knn_opt.fit(X_train_array, y_train)\n",
    "knn_opt_test = knn_opt.predict(X_test_array)\n",
    "\n",
    "confusion_table(knn_opt_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7daff",
   "metadata": {},
   "source": [
    "### ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots(figsize=(8,8))\n",
    "\n",
    "roc_curve_est(knn5,\n",
    "              X_test_array,\n",
    "              y_test,\n",
    "              name='kNN5 (Test)',\n",
    "              color='r',\n",
    "              ax=ax);\n",
    "\n",
    "roc_curve_est(knn500,\n",
    "              X_test_array,\n",
    "              y_test,\n",
    "              name='kNN500 (Test)',\n",
    "              color='y',\n",
    "              ax=ax);\n",
    "\n",
    "roc_curve_est(knn_opt,\n",
    "              X_test_array,\n",
    "              y_test,\n",
    "              name='kNN Optimal (Test)',\n",
    "              color='g',\n",
    "              ax=ax);\n",
    "\n",
    "roc_curve_est(naive,\n",
    "              X_test_array,\n",
    "              y_test,\n",
    "              name='Naive Bayes (Test)',\n",
    "              color='m',\n",
    "              ax=ax);\n",
    "\n",
    "roc_curve_pred(y_test,\n",
    "               probs_test,\n",
    "               name='Logistic:Prob (Test)',\n",
    "               color='b',\n",
    "               ax=ax);\n",
    "#fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0de38",
   "metadata": {},
   "source": [
    "# Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9145b8",
   "metadata": {},
   "source": [
    "### Of the models that were built in this notebook, which would you choose to implement? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca9827",
   "metadata": {},
   "source": [
    "Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04073d86",
   "metadata": {},
   "source": [
    "### Suppose we \"build\" a model on this data that **always predicts true**, i.e., that every customer will purchase Citrus Hill rather than Minute Maid orange juice. What would be the total misclassification rate on this test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b8ba0",
   "metadata": {},
   "source": [
    "You can hard code the exact number to at least **three** decimal places, or you can code a formula that correcly calculates this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c922532",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_rate = #fillin\n",
    "print(misclassification_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
